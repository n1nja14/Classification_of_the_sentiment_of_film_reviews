{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce9a97-7846-4290-8a39-d7a531b3e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d54862-4fb9-41fe-8dbd-f152c45c9d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n",
    "print(f\"Original dataset size: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b050407f-8121-461e-aeb9-f3aab01bb3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rating(review):\n",
    "    \"\"\"Генерация реалистичных оценок на основе содержания отзыва\"\"\"\n",
    "    strong_positive = ['masterpiece', 'excellent', 'perfect', 'outstanding', 'brilliant']\n",
    "    moderate_positive = ['great', 'good', 'wonderful', 'enjoyable', 'recommend']\n",
    "    neutral = ['average', 'mediocre', 'adequate', 'passable', 'acceptable']\n",
    "    moderate_negative = ['poor', 'bad', 'disappointing', 'weak', 'lacking']\n",
    "    strong_negative = ['awful', 'terrible', 'horrible', 'worst', 'waste']\n",
    "    \n",
    "    strong_pos_count = sum(1 for word in strong_positive if word in review.lower())\n",
    "    mod_pos_count = sum(1 for word in moderate_positive if word in review.lower())\n",
    "    neutral_count = sum(1 for word in neutral if word in review.lower())\n",
    "    mod_neg_count = sum(1 for word in moderate_negative if word in review.lower())\n",
    "    strong_neg_count = sum(1 for word in strong_negative if word in review.lower())\n",
    "    \n",
    "    total_score = (strong_pos_count * 2) + mod_pos_count - mod_neg_count - (strong_neg_count * 2)\n",
    "    \n",
    "    if total_score >= 3:\n",
    "        return 5\n",
    "    elif total_score >= 1:\n",
    "        return 4\n",
    "    elif total_score == 0:\n",
    "        return 3\n",
    "    elif total_score >= -2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2716f06-f4d4-4178-9730-b9dc0ad81b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем \n",
    "df['rating'] = df['review'].apply(generate_rating)\n",
    "df['class_label'] = df['rating'] - 1  # Конвертируем в 0-4\n",
    "\n",
    "# Анализ\n",
    "print(\"\\nRealistic rating distribution:\")\n",
    "rating_dist = df['rating'].value_counts().sort_index()\n",
    "print(rating_dist)\n",
    "\n",
    "# Визуализация \n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=rating_dist.index, y=rating_dist.values, palette=\"viridis\")\n",
    "plt.title('Distribution of Movie Ratings', fontsize=16)\n",
    "plt.xlabel('Rating', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.0f}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='center', \n",
    "                xytext=(0, 9), \n",
    "                textcoords='offset points',\n",
    "                fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rating_distribution.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebee957-c3dc-4f57-9ce7-71721c9fec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['review'].values, df['class_label'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, stratify=y_train, random_state=42)\n",
    "\n",
    "print(f\"\\nTrain size: {len(x_train)}\")\n",
    "print(f\"Validation size: {len(x_val)}\")\n",
    "print(f\"Test size: {len(x_test)}\")\n",
    "\n",
    "# Расчет весов для устранения дисбаланса\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(\"\\nClass weights:\", class_weights.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bddc74c-1b21-4378-820d-43f687b97575",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76786f27-e675-4251-957f-781a0da14feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_len=256):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        label = self.labels[item]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090356fe-3d54-4c60-9aeb-df1cc8274a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = ReviewDataset(x_train, y_train, tokenizer, MAX_LEN)\n",
    "val_dataset = ReviewDataset(x_val, y_val, tokenizer, MAX_LEN)\n",
    "test_dataset = ReviewDataset(x_test, y_test, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbfb3ef-08ad-4545-9a19-aef3bb133cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=5,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c016c7e-e4f2-407b-97f4-c7984ffdc935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка \n",
    "EPOCHS = 4\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0.1 * total_steps,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14146e2-c035-499b-9605-08fd050e25f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device, scheduler, class_weights=None):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Взвешивание потерь для учета дисбаланса классов\n",
    "        if class_weights is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    avg_loss = np.mean(losses)\n",
    "    accuracy = correct_predictions.double() / len(data_loader.dataset)\n",
    "    \n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7efc46-26de-41ff-a000-4f3256d90dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, device, class_weights=None):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluation\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            \n",
    "            if class_weights is not None:\n",
    "                loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                logits = outputs.logits\n",
    "                loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = np.mean(losses)\n",
    "    accuracy = correct_predictions.double() / len(data_loader.dataset)\n",
    "    \n",
    "    return avg_loss, accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76584fd-e7c0-429e-ba7a-85ea0a6c6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        class_weights\n",
    "    )\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc.cpu().item())\n",
    "    \n",
    "    val_loss, val_acc, _, _ = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        device,\n",
    "        class_weights\n",
    "    )\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc.cpu().item())\n",
    "    \n",
    "    print(f\"Train loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Validation loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc\n",
    "        print(\"Saved best model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fc249-8d32-401f-8140-64f43a402bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# потери\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], 'b-o', label='Training Loss')\n",
    "plt.plot(history['val_loss'], 'r-o', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss', fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# точность\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], 'b-o', label='Training Accuracy')\n",
    "plt.plot(history['val_acc'], 'r-o', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy', fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('learning_curves.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c7851-1d7c-4025-a7af-3a2f601e23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "model = model.to(device)\n",
    "\n",
    "# Оценка на тестовом наборе\n",
    "test_loss, test_acc, all_preds, all_labels = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    device,\n",
    "    class_weights\n",
    ")\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e2410c-1dce-474b-8c20-895d668d05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['1', '2', '3', '4', '5'], \n",
    "            yticklabels=['1', '2', '3', '4', '5'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted Ratings', fontsize=14)\n",
    "plt.ylabel('True Ratings', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb2605-2c08-49fb-9ce6-834974418c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(all_labels, all_preds, target_names=['1', '2', '3', '4', '5'], output_dict=True)\n",
    "print(classification_report(all_labels, all_preds, target_names=['1', '2', '3', '4', '5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163252b6-d4ea-426b-b751-23907f5ad7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "class_names = ['1', '2', '3', '4', '5']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(3, 1, i+1)\n",
    "    values = [report[class_name][metric] for class_name in class_names]\n",
    "    plt.bar(class_names, values, color=sns.color_palette(\"viridis\", 5))\n",
    "    plt.title(f'{metric.capitalize()} per Class', fontsize=14)\n",
    "    plt.ylabel(metric, fontsize=12)\n",
    "    plt.ylim(0.7, 1.0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Добавление значений на столбцы\n",
    "    for j, v in enumerate(values):\n",
    "        plt.text(j, v + 0.01, f\"{v:.2f}\", ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_metrics.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33953f-6a58-4fa8-ac1c-0535481f1467",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"bert_sentiment_model\")\n",
    "tokenizer.save_pretrained(\"bert_sentiment_model\")\n",
    "print(\"\\nModel and tokenizer saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
